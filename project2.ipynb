{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP90051 Project 2\n",
    "**Name:** *enter your name here*\n",
    "\n",
    "**Student ID:** *your id here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can add additional imports here\n",
    "import copy\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not edit this cell\n",
    "# load the data files (download from the LMS)\n",
    "embedded_images = np.load('images.npy')\n",
    "labels = np.load('labels.npy')  # 19280 excerpts\n",
    "\n",
    "# split into pool & testing\n",
    "X_pool, X_test, y_pool, y_test = train_test_split(embedded_images, labels, \n",
    "                                                  test_size=0.5, random_state=1234, shuffle=True)\n",
    "\n",
    "# sample a seed set\n",
    "np.random.seed(1234)\n",
    "label2id = defaultdict(list)\n",
    "for i, label in enumerate(y_pool):\n",
    "    label2id[label].append(i)  # ids in each class\n",
    "seed_set = []\n",
    "for label, ids in label2id.items():\n",
    "    seed_set.extend(np.random.choice(ids, size=10, replace=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Applying logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def train_logistic_regression(X, y, **args):\n",
    "    \"\"\"\n",
    "    Train a logistic regression model on dataset (X, y) and return trained model.\n",
    "    X: matrix of real values, size n x d\n",
    "    y: vector of string labels, size n\n",
    "    args: optional arguments e.g., for hyper-parameters\n",
    "    \"\"\"\n",
    "    # your code here\n",
    "    clf = LogisticRegression(solver='liblinear')\n",
    "    clf.fit(X, y)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_logistic_regression_accuracy(Xt, yt, model):\n",
    "    \"\"\"\n",
    "    Apply logistic regression prediction on dataset Xt and evaluate accuracy against yt,\n",
    "    returing the accuracy results as a scalar.\n",
    "    Xt: matrix of real values, size m x d\n",
    "    yt: vector of string labels, size m\n",
    "    \"\"\"\n",
    "    # your code here\n",
    "    return model.score(Xt, yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here for training, evaluating & plotting results\n",
    "from sklearn import preprocessing\n",
    "#label_enc = preprocessing.LabelEncoder()\n",
    "#label_enc.fit(y_pool)\n",
    "\n",
    "#print(label_enc.classes_)\n",
    "#y_pool = label_enc.transform(y_pool)\n",
    "#y_test = label_enc.transform(y_test)\n",
    "#print(len(X_pool), len(y_pool))\n",
    "# 换掉solver之后也不需要label encoder了\n",
    "model = train_logistic_regression(X_pool, y_pool)\n",
    "\n",
    "#model = train_logistic_regression(X_pool, y_pool)\n",
    "#test_res = evaluate_logistic_regression_accuracy(X_test, y_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6011410788381742\n"
     ]
    }
   ],
   "source": [
    "test_res = evaluate_logistic_regression_accuracy(X_test, y_test, model)\n",
    "print(test_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Active learning framework with Random selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_select(X, model, **args):\n",
    "    \"\"\"\n",
    "    Given an unlabelled dataset X, a matrix of n x d, and a model (not used)\n",
    "    returns a vector of scores of length n. Each entry reflects the priority \n",
    "    of the corresponding instance. Higher means better.\n",
    "    \"\"\"\n",
    "    # fill in\n",
    "    # The scores are all random numbers. scores.shape = [n, 1]\n",
    "    return np.random.rand(len(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_based_active_learning(X_pool, y_pool, seed_ids,\n",
    "                               train_func, select_func,\n",
    "                               max_size, batch_size, **args):\n",
    "    \"\"\"\n",
    "    Perform an active learning simulation, which starts by training on a seed set,\n",
    "    then iteratively applies the selection function to rank instances in the pool,\n",
    "    selects the top few instances which are included into the training set and the\n",
    "    process repeats. \n",
    "        X_pool: matrix of n x d\n",
    "        y_pool: vector of string labels, size n\n",
    "        seed_ids: initial labelled set set, as a list of indices [0..n-1] into pool\n",
    "        train_func: function which given (X, y, optional args) returns a trained model\n",
    "        select_func: function which given (X, optional args) returns a sequence of scores\n",
    "        max_size: stopping condition for active learning, when labelled data reaches given size\n",
    "        batch_size: number of instances to be labelled in each iteration\n",
    "        args: optional arguments passed to training and selection function\n",
    "    returns the sequence of trained models \n",
    "    \"\"\"\n",
    "  \n",
    "    # fill in\n",
    "    # Get the seed_set from X_pool\n",
    "    seed_ids = copy.deepcopy(seed_ids)\n",
    "    all_ids = list(range(0, len(y_pool)))\n",
    "    pool_ids = [idx for idx in range(len(X_pool)) if idx not in seed_ids]\n",
    "    \n",
    "    model = None\n",
    "    while len(seed_ids) <= max_size:\n",
    "        print(len(seed_ids), end='  ')\n",
    "        seed_X = [X_pool[idx] for idx in seed_ids]\n",
    "        seed_y = [y_pool[idx] for idx in seed_ids]\n",
    "        assert len(seed_X) == len(seed_y)\n",
    "\n",
    "        model = train_func(seed_X, seed_y)\n",
    "        scores = select_func(X_pool, model)\n",
    "        \n",
    "        score_with_ids = []\n",
    "        for i, val in enumerate(scores):\n",
    "            score_with_ids.append([val, i])\n",
    "        #sorted(score_with_ids, reverse=True)\n",
    "        \n",
    "        # Only add those not-exist in seed_ids from score_with_idx into seed_ids\n",
    "        select_for_seed(seed_ids, score_with_ids, batch_size)\n",
    "        \n",
    "    return model, seed_ids\n",
    "            \n",
    "def select_for_seed(seed_ids, score_with_ids, batch_size):\n",
    "    count = 0\n",
    "    score_with_ids = sorted(score_with_ids, reverse=True)\n",
    "    #print(score_with_ids)\n",
    "    for elem in score_with_ids:\n",
    "        idx = elem[1]\n",
    "        if idx not in seed_ids:\n",
    "            seed_ids.append(idx)\n",
    "            count += 1\n",
    "        else:\n",
    "            continue\n",
    "        if count >= batch_size:\n",
    "            return \n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300  360  420  480  540  600  "
     ]
    }
   ],
   "source": [
    "batch = 60\n",
    "max_size = 600\n",
    "models_random, seed1  = pool_based_active_learning(X_pool, y_pool, seed_set, \n",
    "                                    train_logistic_regression, random_select, \n",
    "                                    max_size, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3689834024896266\n"
     ]
    }
   ],
   "source": [
    "## your code here for evaluation of accuracy and plotting of results\n",
    "test_res = evaluate_logistic_regression_accuracy(X_test, y_test, models_random)\n",
    "print(test_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Uncertainty sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "def logistic_regression_entropy_select(X, model, **args):\n",
    "    \"\"\"\n",
    "    Given an unlabelled dataset X, a matrix of n x d, and a discriminative model \n",
    "    P(y|x), returns a vector of n entropy values.\n",
    "    \"\"\"\n",
    "    # fill in\n",
    "    pass\n",
    "    # X.shape (N_samples, N_features)\n",
    "    proba = model.predict_proba(X)\n",
    "    # proba.shape (N_samples, N_classes)\n",
    "    entropy_list = []\n",
    "    for elem in proba:\n",
    "        entropy_list.append(entropy(elem))\n",
    "        \n",
    "    return entropy_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300  360  420  480  540  600  "
     ]
    }
   ],
   "source": [
    "batch = 60\n",
    "max_size = 600\n",
    "models_us, seed2 = pool_based_active_learning(X_pool, y_pool, seed_set, \n",
    "                                 train_logistic_regression, \n",
    "                                 logistic_regression_entropy_select, \n",
    "                                 max_size, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3587136929460581\n"
     ]
    }
   ],
   "source": [
    "## your code here for evaluation of accuracy and plotting of results\n",
    "test_res = evaluate_logistic_regression_accuracy(X_test, y_test, models_us)\n",
    "print(test_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Query by committee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't forget to provide function descriptive comments, like those provided in templates above\n",
    "\n",
    "def query_by_committee_vote_entropy(X, model, **args):\n",
    "    pass\n",
    "\n",
    "def query_by_committee_soft_vote_entropy(X, model, **args):\n",
    "    pass\n",
    "\n",
    "def query_by_committee_KL(X, model, **args):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_committee(X, y, **args):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here for training, evaluation, and plotting code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hierarchical sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
